{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "963d4c49",
      "metadata": {
        "id": "963d4c49"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc(\"font\", size=14)\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2ab13284",
      "metadata": {
        "id": "2ab13284"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "#from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
        "from torch.optim import Adam, SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "b8AnOlNadT7S"
      },
      "id": "b8AnOlNadT7S",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qAVc-nBHXw8l",
        "outputId": "ce572af3-c36c-430c-b608-5db6345b3674"
      },
      "id": "qAVc-nBHXw8l",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "044a3329",
      "metadata": {
        "id": "044a3329"
      },
      "outputs": [],
      "source": [
        "train_img = []\n",
        "train_labels = []\n",
        "\n",
        "test_img = []\n",
        "test_labels = []\n",
        "\n",
        "#path_train = ('/Users/johndufek/Downloads/archive (2)/Training/')# code for local directory (e.g. in jupyter)\n",
        "#path_test = ('/Users/johndufek/Downloads/archive (2)/Testing/')\n",
        "path_train = ('/content/gdrive/MyDrive/archive (2)/Training/')\n",
        "path_test = ('/content/gdrive/MyDrive/archive (2)/Testing/')\n",
        "\n",
        "img_size= 300\n",
        "\n",
        "for i in os.listdir(path_train):\n",
        "    for j in os.listdir(path_train+i):\n",
        "        train_img.append (cv2.resize(cv2.imread(path_train+i+'/'+j), (img_size,img_size)))\n",
        "        train_labels.append(i)\n",
        "\n",
        "for i in os.listdir(path_test):\n",
        "    for j in os.listdir(path_test+i):\n",
        "        test_img.append (cv2.resize(cv2.imread(path_test+i+'/'+j), (img_size,img_size)))\n",
        "        test_labels.append(i)\n",
        "\n",
        "train_img = (np.array(train_img))\n",
        "test_img = (np.array(test_img))\n",
        "\n",
        "\n",
        "train_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(train_labels)]\n",
        "test_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(test_labels)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e373af12",
      "metadata": {
        "id": "e373af12"
      },
      "outputs": [],
      "source": [
        "#os.listdir('/content/gdrive/MyDrive/archive (2)/Training/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper params\n",
        "epochs = 30\n",
        "#batch_size\n",
        "lrn_rate = 0.005\n"
      ],
      "metadata": {
        "id": "vnqptHbqtLHQ"
      },
      "id": "vnqptHbqtLHQ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform function to normalize photo data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5,0.5,0.5],\n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "uQrQeDEK8x6x"
      },
      "id": "uQrQeDEK8x6x",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Training and Validation data sets\n",
        "train_x, val_x, train_y, val_y = train_test_split(np.array(train_img), np.array(train_labels), test_size = 0.20)"
      ],
      "metadata": {
        "id": "kzdxFhUjA2JS"
      },
      "id": "kzdxFhUjA2JS",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize image data\n",
        "train_load=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(path_train,transform=transform),\n",
        "    batch_size=64, shuffle=True\n",
        ")\n",
        "test_load=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(path_test,transform=transform),\n",
        "    batch_size=32, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "u2I15QMpCKVz"
      },
      "id": "u2I15QMpCKVz",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual Network With Nodes\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 15, 3)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(15, 25, 3)\n",
        "    self.conv3 = nn.Conv2d(25, 30, 3)\n",
        "    self.fc1 = nn.Linear(30*17*17, 300)\n",
        "    self.fc2 = nn.Linear(300, 100)\n",
        "    self.fc3 = nn.Linear(100, 4)\n",
        "    self.bn= nn.BatchNorm2d(num_features=15)\n",
        "    self.bn2=nn.BatchNorm2d(num_features=30)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.bn(self.conv1(x))))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = self.pool(F.relu(self.bn2(self.conv3(x))))\n",
        "    x = x.view(-1,30*17*17)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "17mtIVUE4gYe"
      },
      "id": "17mtIVUE4gYe",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_load)\n",
        "images,labels = next(dataiter)\n"
      ],
      "metadata": {
        "id": "tkEoNFzmfYol"
      },
      "id": "tkEoNFzmfYol",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv1 = nn.Conv2d(3, 15, 3)\n",
        "pool = nn.MaxPool2d(2, 2)\n",
        "conv2 = nn.Conv2d(15, 25, 3)\n",
        "conv3 = nn.Conv2d(25, 30, 3)"
      ],
      "metadata": {
        "id": "WtcaCxvJeqdq"
      },
      "id": "WtcaCxvJeqdq",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Figure out number of inputs going into the first linear layer.\n",
        "x = conv1(images)\n",
        "x = pool(x)\n",
        "x = conv2(x)\n",
        "x = pool(x)\n",
        "x = conv3(x)\n",
        "x = pool(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0aI6zv2nipOc",
        "outputId": "1617ef53-c644-4c27-cad6-d9ef060b4fdf"
      },
      "id": "0aI6zv2nipOc",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 30, 17, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy Loss and Stochastic Gradient Descent\n",
        "model = CNN().to(device)\n",
        "loss_f = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr = lrn_rate)\n",
        "\n",
        "n = len(train_load)\n",
        "for epoch in range(epochs):\n",
        "  train_acc = 0\n",
        "  train_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  for (images,labels) in iter(train_load):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        x=model(images)\n",
        "        loss=loss_f(x,labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "\n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(x.data,1)\n",
        "\n",
        "        train_acc+=int(torch.sum(prediction==labels.data))\n",
        "\n",
        "  train_acc=train_acc/n\n",
        "  train_loss=train_loss/n\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  test_acc=0.0\n",
        "  for (images,labels) in iter(test_load):\n",
        "      if torch.cuda.is_available():\n",
        "          images=Variable(images.cuda())\n",
        "          labels=Variable(labels.cuda())\n",
        "\n",
        "      x=model(images)\n",
        "      _,prediction=torch.max(x.data,1)\n",
        "      test_acc+=int(torch.sum(prediction==labels.data))\n",
        "\n",
        "  test_acc=test_acc/len(test_load)\n",
        "\n",
        "\n",
        "  print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_acc)+' Test Accuracy: '+str(test_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4CzZ9bXMklkd",
        "outputId": "a0f457d3-47e4-464f-e21d-e89f6c0ec4ee"
      },
      "id": "4CzZ9bXMklkd",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Train Loss: tensor(125.0634) Train Accuracy: 36.28888888888889 Test Accuracy: 8.615384615384615\n",
            "Epoch: 1 Train Loss: tensor(45.2104) Train Accuracy: 45.08888888888889 Test Accuracy: 12.23076923076923\n",
            "Epoch: 2 Train Loss: tensor(38.9879) Train Accuracy: 47.82222222222222 Test Accuracy: 12.615384615384615\n",
            "Epoch: 3 Train Loss: tensor(32.9402) Train Accuracy: 50.62222222222222 Test Accuracy: 15.692307692307692\n",
            "Epoch: 4 Train Loss: tensor(30.5243) Train Accuracy: 50.91111111111111 Test Accuracy: 15.153846153846153\n",
            "Epoch: 5 Train Loss: tensor(27.0825) Train Accuracy: 52.266666666666666 Test Accuracy: 16.0\n",
            "Epoch: 6 Train Loss: tensor(22.5856) Train Accuracy: 54.68888888888889 Test Accuracy: 15.23076923076923\n",
            "Epoch: 7 Train Loss: tensor(22.4229) Train Accuracy: 55.13333333333333 Test Accuracy: 17.76923076923077\n",
            "Epoch: 8 Train Loss: tensor(18.6100) Train Accuracy: 56.68888888888889 Test Accuracy: 19.153846153846153\n",
            "Epoch: 9 Train Loss: tensor(16.4322) Train Accuracy: 57.68888888888889 Test Accuracy: 19.846153846153847\n",
            "Epoch: 10 Train Loss: tensor(14.3553) Train Accuracy: 58.71111111111111 Test Accuracy: 20.0\n",
            "Epoch: 11 Train Loss: tensor(12.0733) Train Accuracy: 59.666666666666664 Test Accuracy: 18.615384615384617\n",
            "Epoch: 12 Train Loss: tensor(11.6642) Train Accuracy: 59.62222222222222 Test Accuracy: 20.923076923076923\n",
            "Epoch: 13 Train Loss: tensor(10.4077) Train Accuracy: 60.24444444444445 Test Accuracy: 21.0\n",
            "Epoch: 14 Train Loss: tensor(9.1343) Train Accuracy: 60.6 Test Accuracy: 19.615384615384617\n",
            "Epoch: 15 Train Loss: tensor(7.7442) Train Accuracy: 61.24444444444445 Test Accuracy: 20.615384615384617\n",
            "Epoch: 16 Train Loss: tensor(9.2064) Train Accuracy: 60.644444444444446 Test Accuracy: 21.307692307692307\n",
            "Epoch: 17 Train Loss: tensor(7.6683) Train Accuracy: 61.22222222222222 Test Accuracy: 20.076923076923077\n",
            "Epoch: 18 Train Loss: tensor(7.3544) Train Accuracy: 61.15555555555556 Test Accuracy: 19.076923076923077\n",
            "Epoch: 19 Train Loss: tensor(8.1574) Train Accuracy: 60.977777777777774 Test Accuracy: 20.692307692307693\n",
            "Epoch: 20 Train Loss: tensor(5.2626) Train Accuracy: 62.0 Test Accuracy: 21.0\n",
            "Epoch: 21 Train Loss: tensor(5.7041) Train Accuracy: 61.84444444444444 Test Accuracy: 20.923076923076923\n",
            "Epoch: 22 Train Loss: tensor(4.9322) Train Accuracy: 62.24444444444445 Test Accuracy: 20.53846153846154\n",
            "Epoch: 23 Train Loss: tensor(3.9070) Train Accuracy: 62.68888888888889 Test Accuracy: 20.46153846153846\n",
            "Epoch: 24 Train Loss: tensor(4.9733) Train Accuracy: 62.28888888888889 Test Accuracy: 21.153846153846153\n",
            "Epoch: 25 Train Loss: tensor(5.0531) Train Accuracy: 62.24444444444445 Test Accuracy: 21.53846153846154\n",
            "Epoch: 26 Train Loss: tensor(3.1818) Train Accuracy: 62.86666666666667 Test Accuracy: 20.615384615384617\n",
            "Epoch: 27 Train Loss: tensor(4.2786) Train Accuracy: 62.75555555555555 Test Accuracy: 21.53846153846154\n",
            "Epoch: 28 Train Loss: tensor(2.8333) Train Accuracy: 62.977777777777774 Test Accuracy: 22.076923076923077\n",
            "Epoch: 29 Train Loss: tensor(3.3066) Train Accuracy: 62.84444444444444 Test Accuracy: 21.23076923076923\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}